{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'homegrid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/2309228322.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhomegrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDQN\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'homegrid'"
     ]
    }
   ],
   "source": [
    "# test.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from homegrid.DQN import DQNAgent\n",
    "import json\n",
    "import time\n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Create a function to log output to both console and file\n",
    "class Logger:\n",
    "    def __init__(self, log_file):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(log_file, \"w\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "        self.log.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "\n",
    "def load_agent(\n",
    "    checkpoint_path=None, env_name=\"homegrid-task\", episodes=0, use_gpu=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a new DQNAgent instance and loads from checkpoint if provided.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path: Path to checkpoint file (can be a specific path or episode number)\n",
    "        env_name: Name of the environment\n",
    "        episodes: Number of episodes to train\n",
    "        use_gpu: Whether to use GPU acceleration (if available)\n",
    "\n",
    "    Returns:\n",
    "        Loaded agent\n",
    "    \"\"\"\n",
    "    if use_gpu:\n",
    "        # Optimizing CUDA performance\n",
    "        if torch.cuda.is_available():\n",
    "            # Set to benchmark mode for better performance when input sizes don't change much\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cudnn.deterministic = False\n",
    "\n",
    "    agent = DQNAgent(\n",
    "        env_name=env_name, episodes=episodes, checkpoint_dir=checkpoint_dir\n",
    "    )\n",
    "\n",
    "    # Track the episode number of the loaded checkpoint for proper numbering of future checkpoints\n",
    "    loaded_episode = 0\n",
    "\n",
    "    if checkpoint_path is not None:\n",
    "        # Handle both direct paths and episode numbers\n",
    "        if isinstance(checkpoint_path, int):\n",
    "            loaded_episode = checkpoint_path\n",
    "            checkpoint_path = os.path.join(\n",
    "                training_dir, f\"model_checkpoint_{checkpoint_path}.pth\"\n",
    "            )\n",
    "\n",
    "        elif str(checkpoint_path) == \"best\":\n",
    "            checkpoint_path = os.path.join(training_dir, \"best_model.pth\")\n",
    "            # For \"best\" model, try to extract the episode number from the checkpoint\n",
    "            # This will be set from the checkpoint data below\n",
    "\n",
    "        elif str(checkpoint_path) == \"final\":\n",
    "            # Look for the most recent final model\n",
    "            final_models = []\n",
    "            final_models.extend(\n",
    "                [\n",
    "                    os.path.join(training_dir, f)\n",
    "                    for f in os.listdir(training_dir)\n",
    "                    if f.startswith(\"final_model_\") and f.endswith(\".pth\")\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if final_models:\n",
    "                # Sort by modification time, newest first\n",
    "                checkpoint_path = sorted(\n",
    "                    final_models, key=os.path.getmtime, reverse=True\n",
    "                )[0]\n",
    "\n",
    "        # Load the model\n",
    "        print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "        # Load checkpoint with proper format\n",
    "        checkpoint = torch.load(\n",
    "            checkpoint_path, map_location=device, weights_only=False\n",
    "        )\n",
    "        agent.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        if \"optimizer_state_dict\" in checkpoint:\n",
    "            agent.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        if \"epsilon\" in checkpoint:\n",
    "            agent.epsilon = checkpoint[\"epsilon\"]\n",
    "        if \"total_steps\" in checkpoint:\n",
    "            agent.total_steps = checkpoint[\"total_steps\"]\n",
    "        if \"episode\" in checkpoint:\n",
    "            loaded_episode = checkpoint[\"episode\"]\n",
    "            print(f\"Loaded from episode {loaded_episode}\")\n",
    "\n",
    "        # Store the loaded episode number in the agent for proper checkpoint naming\n",
    "        agent.previous_episode = loaded_episode\n",
    "\n",
    "        print(\n",
    "            f\"Loaded checkpoint with epsilon {agent.epsilon:.4f} and {agent.total_steps} total steps\"\n",
    "        )\n",
    "\n",
    "        # Make sure the target network is synced\n",
    "        agent.update_target_network()\n",
    "        return agent\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "def train_agent(num_episodes=1000, continue_from=None, save_interval=100, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Train an agent from scratch or continue training from a checkpoint,\n",
    "    optimized for GPU acceleration.\n",
    "\n",
    "    Args:\n",
    "        num_episodes: Number of episodes to train\n",
    "        continue_from: Checkpoint path or episode number to continue from\n",
    "        save_interval: How often to save checkpoints (in episodes)\n",
    "        use_gpu: Whether to use GPU acceleration (if available)\n",
    "    \"\"\"\n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Set CUDA optimization parameters if using GPU\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        # Empty cache to free up memory\n",
    "        torch.cuda.empty_cache()\n",
    "        # Set to higher precision for numerical stability\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    # Load agent, continuing from checkpoint if specified\n",
    "    agent = load_agent(continue_from, use_gpu=use_gpu)\n",
    "    agent.checkpoint_interval = save_interval  # Set custom checkpoint interval\n",
    "\n",
    "    # Log training metadata with hardware info\n",
    "    gpu_info = \"None\"\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_info = (\n",
    "            f\"{torch.cuda.get_device_name(0)} - {torch.cuda.device_count()} device(s)\"\n",
    "        )\n",
    "\n",
    "    metadata = {\n",
    "        \"start_time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"timestamp\": timestamp,\n",
    "        \"num_episodes\": num_episodes,\n",
    "        \"continue_from\": str(continue_from) if continue_from else \"None\",\n",
    "        \"device\": str(device),\n",
    "        \"gpu_info\": gpu_info,\n",
    "        \"initial_epsilon\": agent.epsilon,\n",
    "        \"learning_rate\": agent.optimizer.param_groups[0][\"lr\"],\n",
    "        \"batch_size\": agent.batch_size,\n",
    "        \"max_replay_buffer_size\": agent.max_replay_buffer_size,\n",
    "        \"epsilon_decay\": agent.epsilon_decay,\n",
    "        \"worker_threads\": num_workers,\n",
    "    }\n",
    "\n",
    "    # Create training log file\n",
    "    training_log_path = os.path.join(training_dir, f\"training_log_{timestamp}.txt\")\n",
    "    training_log = open(training_log_path, \"w\")\n",
    "    training_log.write(\"=== TRAINING LOG ===\\n\\n\")\n",
    "\n",
    "    # Log metadata\n",
    "    training_log.write(\"TRAINING PARAMETERS:\\n\")\n",
    "    for key, value in metadata.items():\n",
    "        training_log.write(f\"  {key}: {value}\\n\")\n",
    "    training_log.write(\"\\n\")\n",
    "\n",
    "    # Save metadata\n",
    "    metadata_path = os.path.join(training_dir, f\"training_metadata_{timestamp}.json\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    # Print training parameters\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"STARTING TRAINING WITH PARAMETERS:\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Start training with performance monitoring\n",
    "    print(f\"Training agent for {num_episodes} episodes...\")\n",
    "    training_log.write(f\"Starting training for {num_episodes} episodes...\\n\\n\")\n",
    "\n",
    "    # Run training\n",
    "    agent.train(episodes=num_episodes)\n",
    "\n",
    "    # Calculate and log total training time\n",
    "    training_time = time.time() - start_time\n",
    "    minutes = training_time / 60\n",
    "    hours = minutes / 60\n",
    "    time_per_episode = training_time / num_episodes\n",
    "\n",
    "    # Save final model\n",
    "    final_path = os.path.join(training_dir, f\"final_model_{timestamp}.pth\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": agent.model.state_dict(),\n",
    "            \"optimizer_state_dict\": agent.optimizer.state_dict(),\n",
    "            \"epsilon\": agent.epsilon,\n",
    "            \"total_steps\": agent.total_steps,\n",
    "            \"metadata\": metadata,\n",
    "            \"training_time_seconds\": training_time,\n",
    "        },\n",
    "        final_path,\n",
    "    )\n",
    "\n",
    "    # Log training statistics\n",
    "    training_log.write(\"\\n=== TRAINING COMPLETED ===\\n\")\n",
    "    training_log.write(\n",
    "        f\"Total training time: {training_time:.1f} seconds ({minutes:.1f} minutes, {hours:.2f} hours)\\n\"\n",
    "    )\n",
    "    training_log.write(f\"Average time per episode: {time_per_episode:.2f} seconds\\n\")\n",
    "    training_log.write(f\"Final epsilon: {agent.epsilon:.4f}\\n\")\n",
    "    training_log.write(f\"Total steps: {agent.total_steps}\\n\")\n",
    "    training_log.write(f\"Final model saved to: {final_path}\\n\")\n",
    "    training_log.close()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"TRAINING COMPLETED\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total time: {training_time:.1f} sec ({minutes:.1f} min, {hours:.2f} hr)\")\n",
    "    print(f\"Time per episode: {time_per_episode:.2f} sec\")\n",
    "    print(f\"Final model saved to: {final_path}\")\n",
    "    print(f\"Training log saved to: {training_log_path}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "def test_agent(checkpoint=\"best\", num_episodes=1000, render=False, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Test a trained agent for a specified number of episodes with GPU acceleration.\n",
    "\n",
    "    Args:\n",
    "        checkpoint: Path to checkpoint file or episode number or \"best\"\n",
    "        num_episodes: Number of episodes to test\n",
    "        render: Whether to render the environment during testing\n",
    "        use_gpu: Whether to use GPU acceleration\n",
    "    \"\"\"\n",
    "    # Use the same timestamp for logging consistency\n",
    "    test_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Setup for GPU testing\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Load the agent from checkpoint\n",
    "    agent = load_agent(checkpoint, use_gpu=use_gpu)\n",
    "\n",
    "    # Run testing\n",
    "    print(f\"\\nTesting agent for {num_episodes} episodes...\")\n",
    "    print(f\"Using device: {agent.device}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    average_reward, success_rate = agent.test(episodes=num_episodes, render=render)\n",
    "    test_time = time.time() - start_time\n",
    "\n",
    "    # Calculate statistics\n",
    "    time_per_episode = test_time / num_episodes\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"TESTING RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Total episodes: {num_episodes}\")\n",
    "    print(f\"Testing time: {test_time:.1f} seconds ({test_time/60:.1f} minutes)\")\n",
    "    print(f\"Time per episode: {time_per_episode:.3f} seconds\")\n",
    "    print(f\"Average reward: {average_reward:.4f}\")\n",
    "    print(f\"Success rate: {success_rate:.1f}%\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Save test results with timestamp\n",
    "    result_path = os.path.join(testing_dir, f\"test_results_{test_timestamp}.json\")\n",
    "\n",
    "    results = {\n",
    "        \"checkpoint\": str(checkpoint),\n",
    "        \"num_episodes\": num_episodes,\n",
    "        \"average_reward\": float(average_reward),\n",
    "        \"success_rate\": float(success_rate),\n",
    "        \"test_time_seconds\": float(test_time),\n",
    "        \"time_per_episode\": float(time_per_episode),\n",
    "        \"device\": str(agent.device),\n",
    "        \"timestamp\": test_timestamp,\n",
    "    }\n",
    "\n",
    "    with open(result_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(f\"Test results saved to: {result_path}\")\n",
    "\n",
    "    return average_reward, success_rate\n",
    "\n",
    "\n",
    "def evaluate_checkpoints(\n",
    "    checkpoint_range=(100, 1000, 100), test_episodes=500, use_gpu=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate multiple checkpoints to create a learning curve with GPU acceleration.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_range: Tuple of (start, end, step) for checkpoint evaluation\n",
    "        test_episodes: Number of episodes to test each checkpoint\n",
    "        use_gpu: Whether to use GPU acceleration\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    start, end, step = checkpoint_range\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"EVALUATING CHECKPOINTS: {start} to {end} (step {step})\")\n",
    "    print(f\"Testing {test_episodes} episodes per checkpoint\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Test untrained baseline first\n",
    "    print(\"\\nEvaluating baseline (untrained) agent...\")\n",
    "    baseline_agent = DQNAgent(\n",
    "        checkpoint_dir=checkpoint_dir\n",
    "    )  # Create a new agent with random initialization\n",
    "    start_time = time.time()\n",
    "    baseline_original_reward, baseline_shaped_reward = baseline_agent.test(\n",
    "        episodes=test_episodes\n",
    "    )\n",
    "    baseline_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"Baseline original reward: {baseline_original_reward:.4f}, Shaped reward: {baseline_shaped_reward:.4f} (time: {baseline_time:.1f}s)\"\n",
    "    )\n",
    "    results[0] = {\n",
    "        \"original_reward\": baseline_original_reward,\n",
    "        \"shaped_reward\": baseline_shaped_reward,\n",
    "    }\n",
    "\n",
    "    # Test each checkpoint\n",
    "    checkpoints_tested = 0\n",
    "    total_eval_time = baseline_time\n",
    "\n",
    "    for episode in range(start, end + 1, step):\n",
    "        checkpoint_path = os.path.join(training_dir, f\"model_checkpoint_{episode}.pth\")\n",
    "        print(f\"\\nEvaluating checkpoint at episode {episode}...\")\n",
    "\n",
    "        # Clean up memory between checkpoints\n",
    "        if use_gpu and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Explicitly load checkpoint with weights_only=False\n",
    "        agent = DQNAgent(env_name=\"homegrid-task\", checkpoint_dir=checkpoint_dir)\n",
    "        checkpoint = torch.load(\n",
    "            checkpoint_path, map_location=device, weights_only=False\n",
    "        )\n",
    "        agent.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        if \"optimizer_state_dict\" in checkpoint:\n",
    "            agent.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        if \"epsilon\" in checkpoint:\n",
    "            agent.epsilon = checkpoint[\"epsilon\"]\n",
    "        if \"total_steps\" in checkpoint:\n",
    "            agent.total_steps = checkpoint[\"total_steps\"]\n",
    "        agent.update_target_network()\n",
    "\n",
    "        # Run test\n",
    "        checkpoint_start = time.time()\n",
    "        original_reward, shaped_reward = agent.test(episodes=test_episodes)\n",
    "        checkpoint_time = time.time() - checkpoint_start\n",
    "        total_eval_time += checkpoint_time\n",
    "\n",
    "        # Store results\n",
    "        results[episode] = {\n",
    "            \"original_reward\": original_reward,\n",
    "            \"shaped_reward\": shaped_reward,\n",
    "        }\n",
    "        checkpoints_tested += 1\n",
    "\n",
    "        print(\n",
    "            f\"Checkpoint {episode} original reward: {original_reward:.4f}, Shaped reward: {shaped_reward:.4f} (time: {checkpoint_time:.1f}s)\"\n",
    "        )\n",
    "\n",
    "    # Also test best model if it exists\n",
    "    best_path = os.path.join(training_dir, \"best_model.pth\")\n",
    "    if os.path.exists(best_path):\n",
    "        print(\"\\nEvaluating best model...\")\n",
    "        if use_gpu and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Explicitly load best model with weights_only=False\n",
    "        best_agent = DQNAgent(env_name=\"homegrid-task\", checkpoint_dir=checkpoint_dir)\n",
    "        checkpoint = torch.load(best_path, map_location=device, weights_only=False)\n",
    "        best_agent.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        if \"optimizer_state_dict\" in checkpoint:\n",
    "            best_agent.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        if \"epsilon\" in checkpoint:\n",
    "            best_agent.epsilon = checkpoint[\"epsilon\"]\n",
    "        if \"total_steps\" in checkpoint:\n",
    "            best_agent.total_steps = checkpoint[\"total_steps\"]\n",
    "        best_agent.update_target_network()\n",
    "\n",
    "        # Run test\n",
    "        best_start = time.time()\n",
    "        best_original_reward, best_shaped_reward = best_agent.test(\n",
    "            episodes=test_episodes\n",
    "        )\n",
    "        best_time = time.time() - best_start\n",
    "        total_eval_time += best_time\n",
    "\n",
    "        results[\"best\"] = {\n",
    "            \"original_reward\": best_original_reward,\n",
    "            \"shaped_reward\": best_shaped_reward,\n",
    "        }\n",
    "        print(\n",
    "            f\"Best model original reward: {best_original_reward:.4f}, Shaped reward: {best_shaped_reward:.4f} (time: {best_time:.1f}s)\"\n",
    "        )\n",
    "\n",
    "    # Create learning curve plots for both reward and success rate\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    plt.style.use(\"ggplot\")\n",
    "\n",
    "    episodes = [e for e in results.keys() if isinstance(e, int)]\n",
    "    original_rewards = [results[e][\"original_reward\"] for e in episodes]\n",
    "    shaped_rewards = [results[e][\"shaped_reward\"] for e in episodes]\n",
    "\n",
    "    # Plot rewards\n",
    "    ax1.plot(\n",
    "        episodes, original_rewards, \"o-\", linewidth=2, markersize=8, label=\"Checkpoints\"\n",
    "    )\n",
    "    ax1.axhline(\n",
    "        y=results[0][\"original_reward\"],\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=\"Baseline (Untrained)\",\n",
    "    )\n",
    "\n",
    "    if \"best\" in results:\n",
    "        ax1.axhline(\n",
    "            y=results[\"best\"][\"original_reward\"],\n",
    "            color=\"g\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=2,\n",
    "            label=\"Best Model\",\n",
    "        )\n",
    "\n",
    "    ax1.set_xlabel(\"Training Episodes\", fontsize=14)\n",
    "    ax1.set_ylabel(\"Average Test Original Reward\", fontsize=14)\n",
    "    ax1.set_title(\"Original Reward: Test Performance vs Training Episodes\", fontsize=16)\n",
    "    ax1.legend(fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot shaped rewards\n",
    "    ax2.plot(\n",
    "        episodes,\n",
    "        shaped_rewards,\n",
    "        \"o-\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "        color=\"blue\",\n",
    "        label=\"Checkpoints\",\n",
    "    )\n",
    "    ax2.axhline(\n",
    "        y=results[0][\"shaped_reward\"],\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=\"Baseline (Untrained)\",\n",
    "    )\n",
    "\n",
    "    if \"best\" in results:\n",
    "        ax2.axhline(\n",
    "            y=results[\"best\"][\"shaped_reward\"],\n",
    "            color=\"g\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=2,\n",
    "            label=\"Best Model\",\n",
    "        )\n",
    "\n",
    "    ax2.set_xlabel(\"Training Episodes\", fontsize=14)\n",
    "    ax2.set_ylabel(\"Average Test Shaped Reward\", fontsize=14)\n",
    "    ax2.set_title(\"Shaped Reward: Test Performance vs Training Episodes\", fontsize=16)\n",
    "    ax2.legend(fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Add annotations for key points\n",
    "    for i, episode in enumerate(episodes):\n",
    "        if i == 0 or i == len(episodes) - 1 or (i % 3 == 0 and len(episodes) > 6):\n",
    "            ax1.annotate(\n",
    "                f\"{original_rewards[i]:.3f}\",\n",
    "                (episode, original_rewards[i]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0, 10),\n",
    "                ha=\"center\",\n",
    "                fontsize=9,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "            )\n",
    "            ax2.annotate(\n",
    "                f\"{shaped_rewards[i]:.3f}\",\n",
    "                (episode, shaped_rewards[i]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0, 10),\n",
    "                ha=\"center\",\n",
    "                fontsize=9,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "            )\n",
    "\n",
    "    # Save plot with timestamp\n",
    "    plt_path = os.path.join(testing_dir, f\"learning_curve_{timestamp}.png\")\n",
    "    plt.savefig(plt_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    # Also save as PDF for publication quality\n",
    "    pdf_path = os.path.join(testing_dir, f\"learning_curve_{timestamp}.pdf\")\n",
    "    plt.savefig(pdf_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    # Don't call plt.show() in non-interactive environments\n",
    "    if hasattr(sys, \"ps1\"):  # Check if running in interactive mode\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)  # Close the figure to free memory\n",
    "\n",
    "    # Save detailed results to JSON\n",
    "    results_path = os.path.join(testing_dir, f\"checkpoint_evaluation_{timestamp}.json\")\n",
    "\n",
    "    gpu_info = \"None\"\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_info = (\n",
    "            f\"{torch.cuda.get_device_name(0)} - {torch.cuda.device_count()} device(s)\"\n",
    "        )\n",
    "\n",
    "    # Add metadata to results\n",
    "    evaluation_metadata = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"checkpoint_range\": list(checkpoint_range),\n",
    "        \"test_episodes_per_checkpoint\": test_episodes,\n",
    "        \"checkpoints_tested\": checkpoints_tested + 1,  # +1 for baseline\n",
    "        \"total_evaluation_time_seconds\": total_eval_time,\n",
    "        \"device\": str(device),\n",
    "        \"gpu_info\": gpu_info,\n",
    "    }\n",
    "\n",
    "    # Prepare final results with metadata\n",
    "    final_results = {\n",
    "        \"metadata\": evaluation_metadata,\n",
    "        \"results\": {\n",
    "            str(k): {\n",
    "                \"original_reward\": float(v[\"original_reward\"]),\n",
    "                \"shaped_reward\": float(v[\"shaped_reward\"]),\n",
    "            }\n",
    "            for k, v in results.items()\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Save results\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(final_results, f, indent=4)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"EVALUATION COMPLETED\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total checkpoints tested: {checkpoints_tested + 1}\")\n",
    "    print(f\"Total evaluation time: {total_eval_time:.1f}s ({total_eval_time/60:.1f}m)\")\n",
    "    print(f\"Learning curves saved to: {plt_path}\")\n",
    "    print(f\"Evaluation results saved to: {results_path}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def benchmark_performance(train_episodes=20, test_episodes=100, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Run a quick benchmark to estimate runtime for larger training and testing.\n",
    "\n",
    "    Args:\n",
    "        train_episodes: Small number of episodes to train (default 20)\n",
    "        test_episodes: Number of episodes to test (default 100)\n",
    "        use_gpu: Whether to use GPU acceleration (if available)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with benchmark results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RUNNING PERFORMANCE BENCHMARK\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Initialize a fresh agent for benchmarking\n",
    "    benchmark_agent = DQNAgent(checkpoint_dir=checkpoint_dir)\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        # Warm up the GPU to ensure accurate timing\n",
    "        dummy_tensor = torch.ones(1000, 1000, device=device)\n",
    "        dummy_result = torch.matmul(dummy_tensor, dummy_tensor)\n",
    "        torch.cuda.synchronize()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    # Clear any cache before starting\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Test single episode timing\n",
    "    print(\"\\nTiming single episode performance...\")\n",
    "    single_start = time.time()\n",
    "    benchmark_agent.train(episodes=1)\n",
    "    single_time = time.time() - single_start\n",
    "    results[\"single_episode_time\"] = single_time\n",
    "    print(f\"Single training episode time: {single_time:.3f} seconds\")\n",
    "\n",
    "    # Training benchmark\n",
    "    print(f\"\\nBenchmarking training for {train_episodes} episodes...\")\n",
    "    train_start = time.time()\n",
    "    benchmark_agent.train(episodes=train_episodes)\n",
    "    train_time = time.time() - train_start\n",
    "    avg_episode_time = train_time / train_episodes\n",
    "    results[\"train_time\"] = train_time\n",
    "    results[\"avg_episode_time\"] = avg_episode_time\n",
    "\n",
    "    print(f\"Training completed in {train_time:.2f} seconds\")\n",
    "    print(f\"Average time per episode: {avg_episode_time:.3f} seconds\")\n",
    "\n",
    "    # Testing benchmark\n",
    "    print(f\"\\nBenchmarking testing for {test_episodes} episodes...\")\n",
    "    test_start = time.time()\n",
    "    benchmark_agent.test(episodes=test_episodes)\n",
    "    test_time = time.time() - test_start\n",
    "    avg_test_time = test_time / test_episodes\n",
    "    results[\"test_time\"] = test_time\n",
    "    results[\"avg_test_time\"] = avg_test_time\n",
    "\n",
    "    print(f\"Testing completed in {test_time:.2f} seconds\")\n",
    "    print(f\"Average time per test episode: {avg_test_time:.3f} seconds\")\n",
    "\n",
    "    # Extrapolation estimates\n",
    "    print(\"\\nExtrapolated runtime estimates:\")\n",
    "    for ep_count in [100, 500, 1000, 2000, 5000]:\n",
    "        est_time = avg_episode_time * ep_count\n",
    "        minutes = est_time / 60\n",
    "        hours = minutes / 60\n",
    "\n",
    "        print(\n",
    "            f\"  • {ep_count} episodes: {est_time:.1f} sec ({minutes:.1f} min, {hours:.2f} hr)\"\n",
    "        )\n",
    "\n",
    "    # Test episodes extrapolation\n",
    "    print(\"\\nExtrapolated test runtime estimates:\")\n",
    "    for test_count in [500, 1000, 5000, 10000]:\n",
    "        est_time = avg_test_time * test_count\n",
    "        minutes = est_time / 60\n",
    "\n",
    "        print(f\"  • {test_count} test episodes: {est_time:.1f} sec ({minutes:.1f} min)\")\n",
    "\n",
    "    # Save results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    benchmark_file = os.path.join(testing_dir, f\"benchmark_results_{timestamp}.json\")\n",
    "\n",
    "    # Include hardware info\n",
    "    hw_info = {\n",
    "        \"device\": str(device),\n",
    "        \"cpu_count\": multiprocessing.cpu_count(),\n",
    "        \"timestamp\": timestamp,\n",
    "    }\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        hw_info[\"gpu\"] = torch.cuda.get_device_name(0)\n",
    "        hw_info[\"cuda_version\"] = torch.version.cuda\n",
    "        hw_info[\"gpu_memory_gb\"] = (\n",
    "            torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        )\n",
    "\n",
    "    results[\"hardware_info\"] = hw_info\n",
    "\n",
    "    with open(benchmark_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(\"\\nBenchmark results saved to:\", benchmark_file)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# GLOBAL CONFIGURATION - Easy to modify\n",
    "# ===========================================\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Limit num threads\n",
    "torch.set_num_threads(2)\n",
    "# Limit GPU memory usage to approximately 45% of allocation\n",
    "if torch.cuda.is_available():\n",
    "    # Get total GPU memory\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory\n",
    "    # Set to use only 45% of available memory\n",
    "    torch.cuda.set_per_process_memory_fraction(0.85)\n",
    "    print(f\"Limiting GPU memory usage to 45% of {total_mem/1e9:.2f} GB\")\n",
    "\n",
    "# GPU optimization parameters\n",
    "num_workers = min(\n",
    "    8, multiprocessing.cpu_count()\n",
    ")  # Use up to 8 worker threads for data loading\n",
    "\n",
    "# Generate timestamp for file naming\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "checkpoint_dir = \"checkpoints66\"  ### CHANGE THIS TO THE CORRECT CHECKPOINT DIRECTORY\n",
    "\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "training_dir = os.path.join(checkpoint_dir, \"training\")\n",
    "testing_dir = os.path.join(checkpoint_dir, \"testing\")\n",
    "os.makedirs(training_dir, exist_ok=True)\n",
    "os.makedirs(testing_dir, exist_ok=True)\n",
    "\n",
    "# Set up logging to capture terminal output\n",
    "log_file = os.path.join(testing_dir, f\"terminal_output_{timestamp}.txt\")\n",
    "sys.stdout = Logger(log_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Print GPU information if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\nGPU INFORMATION:\")\n",
    "        gpu_info = {\n",
    "            \"device\": torch.cuda.get_device_name(0),\n",
    "            \"cuda_version\": torch.version.cuda,\n",
    "            \"memory_gb\": f\"{torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\",\n",
    "            \"num_gpus\": torch.cuda.device_count(),\n",
    "        }\n",
    "\n",
    "        print(f\"  Device: {gpu_info['device']}\")\n",
    "        print(f\"  CUDA version: {gpu_info['cuda_version']}\")\n",
    "        print(f\"  Total memory: {gpu_info['memory_gb']}\")\n",
    "        print(f\"  Number of GPUs: {gpu_info['num_gpus']}\")\n",
    "    else:\n",
    "        gpu_info = \"None\"\n",
    "        print(\"\\nNo GPU available - will use CPU for training and evaluation\")\n",
    "\n",
    "    # Current configuration (uncomment the desired option)\n",
    "\n",
    "    \"\"\"\n",
    "    # OPTION 1: Train a new agent from scratch with GPU acceleration\n",
    "    # Highly recommended for sparse reward environments\n",
    "    train_agent(\n",
    "        num_episodes=2000,  # 2K episodes to train (more for sparse rewards)\n",
    "        save_interval=100,  # Save model every 100 episodes\n",
    "        use_gpu=True,  # Use GPU acceleration if available\n",
    "    )\n",
    "    \n",
    "    test_agent(\n",
    "        checkpoint=\"best\",  # Test the best model saved during training\n",
    "        num_episodes=10000,  # 10K test episodes\n",
    "        use_gpu=True,  # Use GPU for faster testing\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    # OPTION 2: Continue training from a previous checkpoint\n",
    "    # Uncomment to use:\n",
    "    \"\"\"\n",
    "    train_agent(\n",
    "        num_episodes=1000,          # Additional episodes to train\n",
    "        continue_from=\"best\",       # Continue from the best model so far\n",
    "        save_interval=100,          # Save checkpoints every 100 episodes\n",
    "        use_gpu=True                # Use GPU acceleration\n",
    "    )\n",
    "    \n",
    "    test_agent(\n",
    "        checkpoint=\"final\",  # Test the final model after continued training\n",
    "        num_episodes=100,  # Test on 1000 episodes\n",
    "        use_gpu=True,  # Use GPU for faster testing\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    # OPTION 3: Test code quickly to check it doesnt break\n",
    "    # Uncomment to use:\n",
    "\n",
    "    # train_agent(\n",
    "    #     num_episodes=10,\n",
    "    #     save_interval=5,\n",
    "    #     use_gpu=True,\n",
    "    # )\n",
    "\n",
    "    # evaluate_checkpoints(\n",
    "    #     checkpoint_range=(\n",
    "    #         5,\n",
    "    #         10,\n",
    "    #         5,\n",
    "    #     ),\n",
    "    #     test_episodes=50,\n",
    "    #     use_gpu=True,\n",
    "    # )\n",
    "\n",
    "    # train_agent(\n",
    "    #     num_episodes=10,\n",
    "    #     continue_from=10,\n",
    "    #     save_interval=5,\n",
    "    #     use_gpu=True,\n",
    "    # )\n",
    "\n",
    "    # evaluate_checkpoints(\n",
    "    #     checkpoint_range=(\n",
    "    #         10,\n",
    "    #         20,\n",
    "    #         5,\n",
    "    #     ),\n",
    "    #     test_episodes=100,\n",
    "    #     use_gpu=True,\n",
    "    # )\n",
    "\n",
    "    # OPTION 4: Evaluate multiple checkpoints to create a learning curve\n",
    "    # Uncomment to use:\n",
    "\n",
    "    train_agent(\n",
    "        num_episodes=10_000,\n",
    "        save_interval=500,\n",
    "        use_gpu=True,\n",
    "    )\n",
    "\n",
    "    evaluate_checkpoints(\n",
    "        checkpoint_range=(\n",
    "            1000,\n",
    "            10_000,\n",
    "            1000,\n",
    "        ),\n",
    "        test_episodes=200,\n",
    "        use_gpu=True,\n",
    "    )\n",
    "\n",
    "    # test_agent(checkpoint=6000, num_episodes=1000, use_gpu=True)\n",
    "\n",
    "    # train_agent(\n",
    "    #     num_episodes=14000,\n",
    "    #     continue_from=6000,\n",
    "    #     save_interval=500,\n",
    "    #     use_gpu=True,\n",
    "    # )\n",
    "\n",
    "    # evaluate_checkpoints(\n",
    "    #     checkpoint_range=(\n",
    "    #         3000,\n",
    "    #         18000,\n",
    "    #         3000,\n",
    "    #     ),\n",
    "    #     test_episodes=10000,\n",
    "    #     use_gpu=True,\n",
    "    # )\n",
    "\n",
    "    # OPTION 5: Quick test of a specific checkpoint\n",
    "    # Uncomment to use:\n",
    "    \"\"\"\n",
    "    test_agent(\n",
    "        checkpoint=1000,            # Test the model saved at episode 1000\n",
    "        num_episodes=100,           # Run 100 test episodes\n",
    "        render=False,               # Don't render the environment\n",
    "        use_gpu=True                # Use GPU acceleration\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    # OPTION 6: Run a quick benchmark to estimate runtime for larger training\n",
    "    # Uncomment to use:\n",
    "\n",
    "    # benchmark_performance(\n",
    "    #     train_episodes=20,  # Quick training benchmark with 20 episodes\n",
    "    #     test_episodes=100,  # Test benchmark with 100 episodes\n",
    "    #     use_gpu=True,  # Use GPU if available\n",
    "    # )\n",
    "\n",
    "    # ===========================================\n",
    "    # OPTION 7: Self-contained hyperparam sweep\n",
    "    # ===========================================\n",
    "\n",
    "    # # Sweep settings\n",
    "    # TRAIN_EPISODES = 4_000  # ~50 min of training\n",
    "    # TEST_EPISODES = 100  # ~3 min of testing\n",
    "    # LRS = [5e-4, 1e-3]\n",
    "    # EDS = [0.9995, 0.99975, 0.9999]\n",
    "    # FIXED_BATCH = 64\n",
    "    # FIXED_REPLAY_BUFFER_SIZE = 100_000\n",
    "    # FIXED_USE_PER = False\n",
    "\n",
    "    # print(\"\\n=== STARTING HYPERPARAMETER SWEEP ===\")\n",
    "    # for lr, ed in product(LRS, EDS):\n",
    "    #     run_tag = f\"lr{lr}_ed{ed}\"\n",
    "    #     run_ckpt = os.path.join(checkpoint_dir, run_tag)\n",
    "    #     os.makedirs(run_ckpt, exist_ok=True)\n",
    "\n",
    "    #     print(f\"\\n--- RUN {run_tag} ---\")\n",
    "    #     # 1) create agent with fresh checkpoint dir\n",
    "    #     agent = DQNAgent(\n",
    "    #         env_name=\"homegrid-task\", episodes=TRAIN_EPISODES, checkpoint_dir=run_ckpt\n",
    "    #     )\n",
    "    #     # 2) set hyperparameters\n",
    "    #     agent.alpha = lr\n",
    "    #     agent.epsilon_decay = ed\n",
    "    #     agent.batch_size = FIXED_BATCH\n",
    "    #     agent.max_replay_buffer_size = FIXED_REPLAY_BUFFER_SIZE\n",
    "    #     agent.use_per = FIXED_USE_PER\n",
    "\n",
    "    #     # 3) train\n",
    "    #     print(f\"Training for {TRAIN_EPISODES} episodes (α={lr}, ε-decay={ed})\")\n",
    "    #     agent.train(episodes=TRAIN_EPISODES)\n",
    "\n",
    "    #     # 4) test\n",
    "    #     print(f\"Testing for {TEST_EPISODES} episodes\")\n",
    "    #     avg_reward, avg_shaped = agent.test(episodes=TEST_EPISODES)\n",
    "\n",
    "    #     print(\n",
    "    #         f\"RESULT {run_tag} → avg orig reward: {avg_reward:.3f}, avg shaped: {avg_shaped:.3f}\"\n",
    "    #     )\n",
    "\n",
    "    # print(\"\\n=== SWEEP COMPLETE ===\")\n",
    "\n",
    "    # Close the logger at the end of execution\n",
    "    if isinstance(sys.stdout, Logger):\n",
    "        # Close the log file\n",
    "        sys.stdout.log.close()\n",
    "        # Restore original stdout\n",
    "        sys.stdout = sys.stdout.terminal\n",
    "        print(f\"Log file saved to: {log_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
